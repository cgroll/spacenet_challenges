{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a57c425-7d5c-47f4-abd4-55e77754f83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "import seaborn as sns\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7564e2c-d04e-461e-98a1-3ad8dfc59c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.path import ProjPaths\n",
    "from src.data.band3_binary_mask_data import Band3BinaryMaskDataset, RandomCropImgAndLabels, ToTensorImgAndLabels\n",
    "from src.models.unet_ptl import UNet\n",
    "from src.metrics import sample_logits_and_labels, logits_to_prediction, classification_cases, prediction_metrics, compute_true_false_classifications_for_sample_and_model\n",
    "from src.visualization.visualize import show_image_and_true_false_classifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0effebc-732d-4d49-8916-748c1a4c88f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "metrics_fpath = ProjPaths.metrics_path / 'unet_ptl_v5.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf14b93f-80fa-4db8-b417-30a1e57b57cb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics = pd.read_csv(metrics_fpath)\n",
    "model_metrics.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3c863fb-6dcd-4a9f-b05a-52d89ae18e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_path = ProjPaths.interim_sn1_data_path / \"test\"\n",
    "test_dataset = Band3BinaryMaskDataset(test_path, transform=transforms.Compose([\n",
    "                                           RandomCropImgAndLabels(384),\n",
    "                                           ToTensorImgAndLabels()\n",
    "                                       ]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d990ad51-57e2-4064-8ff0-9b8406c337d4",
   "metadata": {},
   "source": [
    "## EDA of building cover"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cedbc29-2015-466f-839d-ef0232f8c5bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.histplot(data=model_metrics['building_cover'])\n",
    "plt.title('Frequency of building land cover')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e8a2ae-7446-48a6-8083-2d59065d1a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "images_without_buildings = np.round(model_metrics.query('building_cover == 0').shape[0] / model_metrics.shape[0] * 100, 2)\n",
    "print(f'{images_without_buildings} % of images do not have any building pixels')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8e2bb-1fe1-4917-bf12-963445a44030",
   "metadata": {},
   "source": [
    "## Find patterns in metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e10c009-8c7d-4f7d-8028-533bae28a301",
   "metadata": {},
   "source": [
    "The less land that is covered by buildings in the image, the higher the accuracy. The intuitive edge case is when almost no building needs to be detected at all, because in such a case the very naive model that predicts \"no building\" all the time would already achieve a good accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e51a56-1e82-4552-98e8-e0f8a10f82d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='building_cover', y='accuracy', data=model_metrics)\n",
    "plt.title('Accuracy as a function of fractional building cover per image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1c06b17-a0fd-488c-a0b1-383d952638b2",
   "metadata": {},
   "source": [
    "This effect is much less visible for Jaccard index values. The reason for this is that the Jaccard index better corrects for the overall number of pixels with buildings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dbc6831-59ce-44f0-b425-cec46434a9f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='building_cover', y='jaccard', data=model_metrics)\n",
    "plt.title('Jaccard index as a function of fractional building cover per image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce68d52-883e-41de-8ce8-9f307793b2c5",
   "metadata": {},
   "source": [
    "A (rather similar) alternative to the Jaccard index would be the dice index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a972e23e-06cd-4c56-b011-89ffbbc61ac0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sns.scatterplot(x='jaccard', y='dice', data=model_metrics)\n",
    "plt.title('Comparison of dice index and jaccard index')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e4d5e-9f7d-47a5-b7c5-6242348cb20c",
   "metadata": {},
   "source": [
    "Inspect model bias: are there generally more or less buildings predicted?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6fee98-6651-411c-93f8-cdee65a0bad0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_predicted_positives = ((model_metrics['true_pos'] + model_metrics['false_pos'])/model_metrics['n_pixels']).mean()\n",
    "avg_building_cover = model_metrics['building_cover'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6688f985-f875-4256-a53e-73dbab303623",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_predicted_positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ad966f-1e39-4aaf-a59c-4563dc934dd1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "avg_building_cover"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3be16eeb-d9b3-4b6e-84aa-9c65433d2543",
   "metadata": {},
   "source": [
    "## Evaluate model for individual samples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43d174e7-5156-40e7-854e-9580d3a64795",
   "metadata": {},
   "source": [
    "Here we will use our UNet Pytorch Lightning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbff7b9f-5320-4393-b0e9-127000154697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "chkpt_path = ProjPaths.model_path / 'unet' / 'unet_ptl_v5' / 'checkpoints' / 'best_model-unet-epoch=15-val_loss=0.09.ckpt'\n",
    "model = UNet.load_from_checkpoint(chkpt_path)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96fbf44-918e-474d-a05a-80b26bc80ff0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_true_false_classifications(this_sample_id):\n",
    "    \n",
    "    sample = test_dataset[this_sample_id]\n",
    "    classes_masked = compute_true_false_classifications_for_sample_and_model(sample, model, DEVICE)\n",
    "    \n",
    "    return sample, classes_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6fd59a1-1f69-4af3-b83a-341178af67a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "this_sample_id = 132\n",
    "this_sample_id = 866\n",
    "\n",
    "sample, classes_masked = compute_true_false_classifications(this_sample_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "302d6f4f-dc05-46f4-9128-a780f71bbfb2",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d668f8a6-0c32-4fdb-b026-e08d7e102052",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "show_image_and_true_false_classifications(sample, classes_masked)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "153ffde2-67e9-4e68-adcc-063822d5d50b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = ((classes_masked.data == 1) | (classes_masked.data == 3))*1 # get original prediction from true_pos and false_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8eb347-e2d3-482f-9dcf-f6dbc44bc09e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44bf80aa-ceb7-4fb3-be4c-1ca83e97af06",
   "metadata": {},
   "source": [
    "## Find example cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b6001-7d25-4518-bbeb-69a30eff232f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics.query('jaccard < 0.4').query('building_cover < 0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7200fdd0-744c-4458-96dc-7b6729046a68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_metrics.query('jaccard < 0.4').query('building_cover > 0.2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbb5ef4-1d24-4c07-8612-95214e99120f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sample_ids = [237, 512, 634, 866]\n",
    "\n",
    "for this_sample_id in sample_ids:\n",
    "\n",
    "    sample, classes_masked = compute_true_false_classifications(this_sample_id)\n",
    "    show_image_and_true_false_classifications(sample, classes_masked)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbc3c6a-66b3-4b10-8002-ba8184e535be",
   "metadata": {},
   "source": [
    "TODO: precision, recall, F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92c48d65-01e1-4794-ae68-5bf942a510f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_ids = [test_dataset.image_ids[this_sample_id] for this_sample_id in sample_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d660159-5582-4a35-82d7-3598e7439bb3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80443873-387d-4c60-acfd-9ee134d78ebd",
   "metadata": {},
   "source": [
    "## Multi-spectral images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5039a41-3206-4d2b-9ae3-e79fa8dee548",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "path_8band = ProjPaths.interim_sn1_data_path / 'test' / '8band'\n",
    "fpaths = [path_8band / (f'8band_' + this_image_id + '.tif') for this_image_id in image_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3553b4-5101-4add-a265-8daa3576f664",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fpaths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de4f7c0-24a0-4250-a882-caba1d4caf61",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7c0edd-f171-4625-bdee-5f2514b55804",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_arr = rioxarray.open_rasterio(str(fpaths[3]))\n",
    "img_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1c38bc-422e-4be3-8c56-d536a4b934ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce062616-d312-4ef4-a270-92f421d89a4a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_arr[0].band.rio.crs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac81c83-9b41-4630-a642-de550a725a0f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_arr.plot.imshow(col=\"band\", col_wrap=3, cmap=\"Greys_r\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bde89572-e814-43ce-ac5c-67961fc6c8a8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def scale_values(in_arr):\n",
    "    \n",
    "    arr = in_arr.copy()\n",
    "    \n",
    "    min_val = np.min(arr)\n",
    "    max_val = np.max(arr)\n",
    "    arr_range = max_val - min_val\n",
    "    factor = arr_range / 255\n",
    "    \n",
    "    arr = (arr - min_val)\n",
    "    arr = arr/factor\n",
    "    \n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "822d1c1a-f447-45b6-806c-5ea6ee72ea6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals = img_arr[[4, 3, 2]].values\n",
    "\n",
    "for ii in [0, 1, 2]:\n",
    "    vals[ii, :, :] = scale_values(vals[ii, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c831aaf6-dc89-4bc2-8f9a-546aca43c1b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals_disp = np.moveaxis(vals, 0, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b17744-ca2f-4391-8101-8b9d96eaa529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "vals_disp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcdd724f-7c1d-423a-87df-59f9aa003eb9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.imshow(vals_disp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec19ea8-cbc1-4884-befc-397654415c10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
